[[transactional_topologies]]

== Transactional Topologies 

With Storm you can guarantee message processing by using _ack_ and _fail_ strategy, as mentioned earlier in the book. But what happens if tuples are replayed? How do you make sure you won't overcount?

_Transactional Topologies_ is a new feature, included in Storm 0.7.0, that enables exactly once messaging semantics. This way we can replay tuples in a secure way and make sure we process them only once. Without support for transactional topologies we wouldn't be able to count in a fully-accurate, scalable and fault-tolerant way.

NOTE: Transactional Topologies are an abstraction built on top of standard Storm spouts and bolts.

=== The design

In a transactional topology, Storm uses a mix of parallel and sequential tuple processing. The spout generates batches of tuples, that are processed by the bolts in parallel. Some of those bolts are known as _commiters_, and they commit processed batches in a strictly ordered fashion. This means that if we have two batches, with five tuples each, both tuples will be processed in parallel by the bolts, but the commiter bolts won't commit the second tuple, until the first tuple is committed sucessfully.

This can be described as two different steps, or phases:

- The processing phase: a fully parallel phase, many batches are executed at the same time.
- The commit phase: a strongly ordered phase, batch two is not committed until batch one has committed successfully.

We'll call both of these phases a _Storm Transaction_.

NOTE: When dealing with transactional toplogies, it is important to be able to replay batch of tuples from the source, and sometimes even several times. So make sure your source of data, the one that your spout will be connected to, has the ability to do that.

TIP: Storm uses Zookeeper to store transaction metadata. By default the one used for the topology, will be used to store the metadata. You can change this by overriding the configuration key _transactional.zookeeper.servers_ and _transactional.zookeeper.port_.

=== Transactions in Action

To see how transactions work we'll create a tweeter analytics tool. We'll be reading tweets stored in a redis database, process them through a few bolts and finally store in another redis database the list of all hashtags and their frequency among the tweets, the list of all users and amount of tweets they appear in, and finally a list of users with their hashtags and frequency. 

The topology we'll build for this tool is described in <<FIG801>>.

.Topology overview
[[FIG801]]
image::figs/ch08-transactional-topology.jpg

As you can see, +TweetsTransactionalSpout+ is the spout that will be connecting to our tweets database and will be emitting batches of tuples across the topology. Two different bolts, +UserSplitterBolt+ and +HashtagSplitterBolt+, will will be receiving tuples from the spout. +UserSplitterBolt+ will parse the tweet and look for users, that is words preceded by _@_ and will emit these words in a custom stream called _users_. The +HashatagSplitterBolt+ will also parse the tweet, looking for words preceded by _#_, and will emit these words in a custom stream called _hashtags_. A third bolt, the +UserHashtagJoinBolt+, will receive both streams and will count how many times a hashtag has appeared in a tweet were a user was named. In order to do counting and emitting the result, this bolt will be a +BaseBatchBolt+ (more on that later).

Finally, a last bolt, called +RedisCommitterBolt+, will receive the three streams, the ones generated by +UserSplitterBolt+, +HashtagSplitterBolt+ and +UserHashtagJoinBolt+. It will count everything and once finished processing the batch of tuples, it will send everything to redis, in one transaction. This bolt is a special kind of bolt, explined later in this chapter, known as a _committer bolt_.

Lets see how we can implement the spout in a transactional toplogy.

==== The Spout

The spout in a transactional topology is completely different from a standard spout.

[source,java]
----
public class TweetsTransactionalSpout extends BaseTransactionalSpout<TransactionMetadata>{
----

As you can see in the class definition, +TweetsTransactionalSpout+ extends +BaseTransactionalSpout+ with a generic type. The type you set there is something known as the _transaction metadata_. It will be usee later, to be able to emit batches of tuples from the source.

In our example, +TransactionMetadata+ is defined as:

[source,java]
----
public class TransactionMetadata implements Serializable {
  private static final long serialVersionUID = 1L;

  long from;
  int quantity;

  public TransactionMetadata(long from, int quantity) {
    this.from = from;
    this.quantity = quantity;
  }
}
----

Here we store +from+ and +quantity+, which will tell us exactly how to generate the batch of tuples.

To finish the implementation of the spout, we need to implement the following 3 methods:

[source,java]
----
@Override
public ITransactionalSpout.Coordinator<TransactionMetadata> getCoordinator(
Map conf, TopologyContext context) {
  return new TweetsTransactionalSpoutCoordinator();
}

@Override
public backtype.storm.transactional.ITransactionalSpout.Emitter<TransactionMetadata> getEmitter(
Map conf, TopologyContext context) {
  return new TweetsTransactionalSpoutEmitter();
}

@Override
public void declareOutputFields(OutputFieldsDeclarer declarer) {
  declarer.declare(new Fields("txid", "tweet_id", "tweet"));
}
----

In the +getCoordinator+ method we tell storm which class will coordinate the generation of batches of tuples. With +getEmitter+ we tell storm which class will be responsible for reading batches of tuples from the source and emitting them to a stream in the topology.
And finally, as we already did before, we need to declare which fields are emitted.

===== The RQ class

To make the example easier, we've decided to encapsulate all operations with redis in one single class.

[source,java]
----
public class RQ {
  public static final String NEXT_READ = "NEXT_READ";
  public static final String NEXT_WRITE = "NEXT_WRITE";

  Jedis jedis;

  public RQ() {
    jedis = new Jedis("localhost");
  }

  public long getAvailableToRead(long current) {
    return getNextWrite() - current;
  }

  public long getNextRead() {
    String sNextRead = jedis.get(NEXT_READ);
    if(sNextRead == null)
      return 1;
    return Long.valueOf(sNextRead);
  }

  public long getNextWrite() {
    return Long.valueOf(jedis.get(NEXT_WRITE));
  }

  public void close() {
    jedis.disconnect();
  }

  public void setNextRead(long nextRead) {
    jedis.set(NEXT_READ, ""+nextRead);
  }

  public List<String> getMessages(long from, int quantity) {
    String[] keys = new String[quantity];

    for (int i = 0; i < quantity; i++)
      keys[i] = ""+(i+from);

    return jedis.mget(keys);
  }
}
----

Read carefully the implementation of each method, and make sure you understand what they do.

===== The Coordinator

Lets see the implementation of the coordinator of our example.

[source,java]
----
public static class TweetsTransactionalSpoutCoordinator implements ITransactionalSpout.Coordinator<TransactionMetadata> {
  TransactionMetadata lastTransactionMetadata;
  RQ rq = new RQ();
  long nextRead = 0;

  public TweetsTransactionalSpoutCoordinator() {
    nextRead = rq.getNextRead();
  }

  @Override
  public TransactionMetadata initializeTransaction(BigInteger txid, TransactionMetadata prevMetadata) {
    long quantity = rq.getAvailableToRead(nextRead);
    quantity = quantity > MAX_TRANSACTION_SIZE ? MAX_TRANSACTION_SIZE : quantity;
    TransactionMetadata ret = new TransactionMetadata(nextRead, (int)quantity);

    nextRead += quantity;
    return ret;
  }

  @Override
  public boolean isReady() {
    return rq.getAvailableToRead(nextRead) > 0;
  }

  @Override
  public void close() {
    rq.close();
  }
}
----

It is important to mention that *among the entire topology there will be only one coordinator instance*. 
When the coordinator is instanciated, it retrieves from redis a sequence that tell the coordinator which is the next tweet to read. The first time, this value will be 1, which means that the next tweet to read is the first one.

The first method that will be called is +isReady+. *It will always be called before +initializeTransaction+*, to make sure the source is ready to be read from. You should return +true+ or +false+ accordingly. In this example we retrieve the ammount of tweets and compare them with how many tweets we read. The difference between them is the amount to available tweets to read. If it is greater than 0, it means we have tweets to read.

Finally the +initializeTransaction+ is executed. As you can see, we get +txid+ and +prevMetadata+ as parameters. The first one, is a unique transaction id, generated by storm, which identifies the batch of tuples to be generated. +prevMetadata+ is the metadata, generated by the coordinator, of the previous transaction.

In this example, we first make sure how many tweets are available to read. And once we have sorted that out, we create a new +TransactionMetadata+, indicating which is the first tweets to read +from+, and which is the +quantity+ of tweets to read.

As soon as we return the metadata, Storm stores it, with the +txid+, in zookeeper. This guarantee that if something goes wrong, Storm will be able to replay this with the emitter, to resend the batch.

===== The Emitter

The last part when creating a transactional spout, is implementing the emitter.

Lets start with the implementation:

[source,java]
----
public static class TweetsTransactionalSpoutEmitter implements ITransactionalSpout.Emitter<TransactionMetadata> {

  RQ rq = new RQ();

  public TweetsTransactionalSpoutEmitter() {
  }

  @Override
  public void emitBatch(TransactionAttempt tx, TransactionMetadata coordinatorMeta, BatchOutputCollector collector) {
    rq.setNextRead(coordinatorMeta.from+coordinatorMeta.quantity);
    List<String> messages = rq.getMessages(coordinatorMeta.from, coordinatorMeta.quantity);

    long tweetId = coordinatorMeta.from;

    for (String message : messages) {
      collector.emit(new Values(tx, ""+tweetId, message));
      tweetId++;
    }
  }

  @Override
  public void cleanupBefore(BigInteger txid) {
  }

  @Override
  public void close() {
    rq.close();
  }
}
----

Emitters are the one who will be reading the source and sending tuples to a stream. It is very important for the emitters to be able to always send the same batch of tuples for the same _transaction id_ and _transaction metadata_. This way, if something go wrong during the processing of a batch, Storm will be able to repeat the same _transaction id_ and _transaction metadata_ with the emitter, and make sure the batch of tuples are repeated.
Storm will increase the _attempt id_ in the +TransactionAttempt+. This way we know that the batch is repeated.

The important method here is +emitBatch+. In this method we use the metadata, given as a parameter, to get tweets from redis. We also increase the sequence in redis that keeps track of how many tweets we've read so far. And of course we emit the tweets to the topology.

