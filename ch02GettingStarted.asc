[[getting_started]]
== Getting Started

In this chapter we will create a Storm project and our first Storm topology.

TIP: The following assumes that you have at least version 1.6 of the Java Runtime Environment (JRE) installed. Our recommendation is to use the JRE provided by Oracle, which can be found at (link:www.java.com/downloads/[]) 

[[operation_modes]]
=== Operation Modes

Before we start, it is important to understand _Storm operation modes_. There are two different ways we can run Storm.

==== Local Mode

In this mode, Storm topologies run on our local machine. Local Mode is perfect for development and testing your topology since you'll be able to see how your topology is running and debug it. You can also change different parameters that enable you to see how your topology runs in different cluster configuration environments. We will see more about that later (<<testing_our_topology, Testing our topology>>).

In all of the examples in this chapter we will work in *Local Mode*. 

==== Remote Mode

In Remote Mode you submit your topology to the Storm cluster, so it runs distributed across the machines in the cluster. Remote Mode doesn't show debugging information, which is why it's considered *Production Mode*. However it's possible to run your topology in Remote Mode in a development environment (and it's recommendable to do so). We will show how to do so in a later chapter (<<testing_our_topology, Testing our topology>>)

We will see more about *Remote Mode* in the chapter <<a_real_life_example,A Real Life Example>>

=== Hello world Storm

For this project we will create a simple topology to count words. We can consider this the _Hello World_ of Storm topologies, however it is a very powerful topology because it can scale to virtually infinite size, and with some small modifications we can create a very good statistical system. For example we could modify the project to find trending topics on Twitter.

To create the topology we will use a *spout* that will be responsible for reading the words, a first *bolt* to normalize the words and a second *bolt* to count each word, as we can see in <<getting_started_topology_img,figure 1>>
 

[[getting_started_topology_img]]
image:figs/getting-started-topology.jpg[Fig 1 - Getting started topology]

==== Checking Java installation

The first thing to do to set up our environment is check our Java version. Open a console window and run the command *"java -version"*, You should see something similar to the following:

=======================================================
~$ java -version


java version "1.6.0_26"

Java(TM) SE Runtime Environment (build 1.6.0_26-b03)

Java HotSpot(TM) Server VM (build 20.1-b02, mixed mode)

=======================================================

If not please check your Java installation. (See link:http://www.java.com/download/[])


==== Creating the project

TIP: For Storm development we will use link:http://maven.apache.org/[Apache Maven] although is not necessary be a Maven expert to use Storm, it's recommended to know the basics of how Maven works. You can find more information on the Apache Maven website (link:http://maven.apache.org/[]). 

To create our project we will start by creating a folder where we will place our application (like any Java application).

Next we need to create a pom.xml file. We will use the dependencies and Maven repository set up by nathanmarz (https://github.com/nathanmarz/). These dependencies can be found at https://github.com/nathanmarz/storm/wiki/Maven.  _The Storm Maven dependencies reference all the libraries required to run Storm in_ *Local Mode*

Using these dependencies we can create a pom.xml file with the basic components necessary to run our topology

----
include::code/getting-started/pom.xml[]
----

The application will have the following structure:

===================================
~$ tree getting-started/

    getting-started/
            ├── pom.xml
            └── src
                └── main
                    └── java
                        ├── spouts
                        └── bolts

===================================


=== Creating our first topology

To create our first topology we will create all classes required to run the word count. It's possible that some parts of the example may not be clear at this stage, however we will explain them in further depth in subsequent chapters.  

==== Spout

To create our WordReader spout we will need to write a class that implements IRichSpout (or any IRichSpout subclass). We will see more about how in the chapter on <<spouts,Spouts>>

Our class will be responsible for reading the file and providing each line to a bolt.

TIP: A spout will *emit* a list of defined fields. This architecture enables you to have different kinds of bolts reading the same spout stream, which can then define fields for other bolts to consume and so on.

The most important method that we will need to implement is *public void nextTuple()*, from which we will _emit_ values to be processed by the bolts. In our example the method will read the file and *emit* a value per line.

TIP: A tuple It's a named list of values and this values can be any type of java object (must be serializables, we will see more at the <<advnced_topics,Advanced Topics>> chapter), by default Storm cab serialize primitive types like strings, byte arrays, ArrayList, HashMap and HashSet

The code for the class, including some other methods that will be explained in the chapter on Spouts, is included below:

[source,java]
----
include::code/getting-started/src/main/java/spouts/WordReader.java[]
----


==== Bolts

At this moment we have the spout which will read a file and emite one *tuple*, So We need to create the bolts to precess this lines, to do that We will use two bolts (as we can see at the <<getting_started_topology_img,fig1>>) 

The most important method at the bolt is *void execute(Tuple input)* which is called one time per tuple emited by the bolt and It's here where the bolt will emit new values (if is needed), we will see more about lather in the chapter <<bolts,Bolts>>

TIP: It's important to know that on bolt or spout can emit as tuples as are needed that is when the method *nextTuple* or *execute* are called this could emit 0, 1 or infinites tuples.

The first bolt *WordNormalizer* will be responsible for get each line and *normalize* this splitting the lines, getting an string arrays, putting all words in lower mode and trimming the words,as we can see in the class included below:

TIP: In this class we can see an example of emit many tuples in a single *execute* call, if the method recive the phrase _It is the storm book _ in a single *execute* call this will emit 6 new tuples

[source,java]
----
include::code/getting-started/src/main/java/bolts/WordNormalizer.java[]
----

The next bolt that will implement will be the *WordCounter* which will be responsible for get each word and count it, at the topology finished (when the cleanup is called) we will show all counts
We can see the class:

TIP: Here we can see an example of a bolt that emit nothing

[source,java]
----
include::code/getting-started/src/main/java/bolts/WordCounter.java[]
----


==== The main class

The main class will be where we will create our topology and where we will create a *LocalCluster* object, this object will enable us to test the topology locally in our computer and debug it, really it is a very powerfull class because in conjuntion with the *Config* object we can test locally differents cluster configurations, for example if you use global or class variableis you found the error very fast when test your topology in configurations where change the number of workers that you will use (we will see more about the config objects in the <<topologies, Topologies>> chapter) 

TIP: All your topology nodes should be able to run alone (no shared data between process), because when you run the topology in real cluster these process will run in different processes and different machines

To create our topology we will need create a *TopologyBuilder* using this we will say to storm how all our nodes will stick together and how they exchange the data emited between them. Our topoloy will be defined whith the next code:

[source,java]
--------------------------------------------------------------------------------------------------------
TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("word-reader",new WordReader());
builder.setBolt("word-normalizer", new WordNormalizer()).shuffleGrouping("word-reader");
builder.setBolt("word-counter", new WordCounter()).shuffleGrouping("word-normalizer");
--------------------------------------------------------------------------------------------------------

Here we can see how the spout and the bolts are connected using the *shuffleGrouping*, with this grouping we say to storm that send the message from the node indicated to a shuffle instance node that require the data, you could define many data source for a bolt adding more groupings

The next thing to do it is create a *Config* object where we will set all topology configuration, this will be merged with the the cluster configuration in runtime and send to all nodes after create this calling the *prepare* method.
Our *Config* object will be 

[source,java]
--------------------------------
Config conf = new Config();
conf.put("wordsFile", args[0]);
conf.setDebug(true);
--------------------------------

We can see how we are setting the file to read by the spout using the property _wordsFile_, other important configuration to set it is to put the property *debug* to *true* when we are in development stage, using this property storm will print all mesages exchange between nodes and other debug data very usefull to understand how the topology is running 

As we saw we will need a *LocalCluster* to run the topology, If we were in a real environment, the topology will never finish but for this example We will run the topology and stop this few seconds after to see the results, using the next piece of code:

[source,java]
-----------------------------------------------------------------------------------
LocalCluster cluster = new LocalCluster();
cluster.submitTopology("Getting-Started-Toplogie", conf, builder.createTopology());
Thread.sleep(2000);
cluster.shutdown();
-----------------------------------------------------------------------------------

Using the *createTopology* at the builder object we will create the topology and using the *submitToplogy* method we will run the topology, then we will sleep (the topology will not run in the main class thread) and finish the topology and shutting down the cluster

We can see below, the whole main class:
[source,java]
----
include::code/getting-started/src/main/java/TopologyMain.java[]
----


==== Show in action

text

=== Conclusions

text
