[[bolts]]
== Bolts

As we have seen, Bolts are key components in a Storm cluster.
In this chapter weâ€™ll look at a Bolt's life cycle, some strategies for Bolt design and some examples of how to implement them.

=== Bolt Lifecycle

A Bolt is a component that takes tuples as input and produces tuples as output. When writing a Bolt you will usually implement the +IRichBolt+ interface.
Bolts are created on the client machine, serialized into the topology and submitted to the master machine of the cluster. The cluster launches workers that deserialize the Bolt, call +prepare+ on it and then start processing tuples.

To customize a Bolt you should set parameters in its constructor and save them as instance variables, so they will be serialized when submitting the Bolt to the cluster.

=== Bolt Structure

Bolts have the following methods:

* +declareOutputFields(OutputFieldsDeclarer declarer)+: Declare the output schema for this bolt.
* +prepare(java.util.Map stormConf, TopologyContext context, OutputCollector collector)+: Called just before the bolt starts processing tuples.
* +execute(Tuple input)+: Process a single tuple of input.
* +cleanup()+: Called when a bolt is going to shutdown.

Let's take a look at an example of a Bolt that will split sentences into words.

[source, java]
----
class SplitSentence implements IRichBolt {
    private OutputCollector collector;
    
    public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
        this.collector = collector;
    }

    public void execute(Tuple tuple) {
        String sentence = tuple.getString(0);
        for(String word: sentence.split(" ")) {
            collector.emit(new Values(word));
        }
    }

    public void cleanup() {
    }

    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word"));
    }        
}
----

As you can see this Bolt is very straightforward. It's worth mentioning that in this example there is no message guarantee. This means that if the bolt discards a message for some reason, either because it goes down or because it was deliberately discarded programmatically, the Spout that generated the message will never be notified, and neither will any of the Bolts and Spouts in between.

In many cases you'll want to guarantee message processing through the entire Topology. 

=== Reliable vs Unreliable Bolts

As we said before Storm guarantees that each message sent by a Spout will be fully processed by all Bolts. This is a design consideration, meaning that you will need to decide whether your Bolts guarantee messages.

A Topology is a tree of nodes in which messages (tuples) travel along one or more branches. Each node will +ack(tuple)+ or +fail(tuple)+ so that Storm knows when a message fails and notifies the Spout or Spouts that produced the message.
Since a Storm topology runs in a highly parallelized environment, the best way to keep track of the original Spout instance is to include a reference to the originating Spout in the message tuple. This technique is called Anchoring.
Let's change the SplitSentence Bolt that we just saw so that it guarantees message processing.

[source, java]
----
class SplitSentence implements IRichBolt {
    private OutputCollector collector;
    
    public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
        this.collector = collector;
    }

    public void execute(Tuple tuple) {
        String sentence = tuple.getString(0);
        for(String word: sentence.split(" ")) {
            collector.emit(tuple, new Values(word));
        }
        collector.ack(tuple);
    }

    public void cleanup() {
    }

    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word"));
    }        
}
----

The exact line where the anchoring happens is +collector.emit(tuple, new Values(word));+. As we mentioned above, passing along the tuple enables Storm to keep track of the originating Spouts.
+collector.ack(tuple)+ and +collector.fail(tuple)+ tell a Spout what happened to each message.
Storm will send a fail message to the Spout if you don't call +ack+ or +fail+ within a configurable timeout. The default is 30 seconds.

Of course the Spout needs to take care of the case when a message fails and retry or discard the message accordingly.

=== Multiple streams

A Bolt can emit tuples to multiple streams using +emit(streamId, tuple)+, where +streamId+' is a String that identifies the stream. Then in the +TopologyBuilder+ you can decide which stream to subscribe to.

=== Multiple Anchoring

To use a Bolt to join or aggregate streams you'll need to buffer tuples in memory. In order to message guarantee in this scenario you have to anchor the stream to more than one tuple. This is done by calling +emit+ with a +List+ of tuples.
[source, java]
----
...
List<Tuple> anchors = new ArrayList<Tuple>();
anchors.add(tuple1);
anchors.add(tuple2);
_collector.emit(anchors, values);
...
----

That way any time a bolt acks or fails it notifies the tree, and because the stream is anchored to more than one tuple, all spouts involved are notified.

=== Using IBasicBolt to do acking automatically

As you probably noticed, there are lots of use cases in which you need message guarantees. To make things easier, Storm provides another interface for Bolts called +IBasicBolt+ which calls +ack+ right after the +execute+ method. You can also use a +BasicOutputCollector+ which automatically anchors emitted tuples to input tuples.
