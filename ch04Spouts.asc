[[spouts]]
== Spouts

In this chapter weâ€™ll see the most used strategies to design the entry point of our topologies (spouts) and how we can do these spouts fault-tolerant

=== Reliable vs Unreliable messages

When we design a topology one important thing to take in mind is the message reliable, in other words when a message can't be processed we need to decide what we'll do with the message and what we'll do with the topology, for example if we are processing bank deposit, we can't lost any transaction message but if we are processing millons of tweets looking for some statistic metric and we lost one tweet we can assume that the metric will be ok.

In storm is our responsability guaranting messages and depends on needs of each topology to do these more or less reliable, because each one have their trade-off's, if we do a very reliable topology we must manage the lost messages and probably this use much resources, in the other hand if we decide to have an unreliable topology we will take the caution that if a message is fail we can't do anything.

To manage the reliable in the spout, we can send with our tuple a message id to identify this tuple at the _emit_ time (*collector.emit(new Values(...),tupleId)*), if we do that, we'll be able to use the methods *ack* and *fail* that will be called if a tuple is proceced correctly or if this fail respectively, the fail method could be called if the *collector.fail(tuple)* is called into the target spouts or if the tuple excedes the Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS (max number of seconds before the tuple is full processed) or Config.TOPOLOGY_MAX_SPOUT_PENDING (number of tuples emited without get ack or fail) topology parameters

TIP: A tuple with a message id will be full processed when: the tuple has been processed by all target bolts and all bolts anchored to the tuple (if there) have processed this tuple too (we will see how anchore a bolt to a tuple into the chapter <<bolts,Bolts>>)

We will use the bank example to resend a transaction if something fails processing it and we fail if we receive 2 errors processing one transaction. To do that we'll create an Spout that will send 100 random transactions Ids and an bolt that will fail 80% of the tuples received (you can found the complete example at link:https://github.com/storm-book/examples-ch04-spouts/[ch04-spout examples]) 
To emit the tuples will use a _Map_ where we'll put all the transaction message that we want to send so it will make very easy re-send messages.

[source, java]
----
public void nextTuple() {
    if(!toSend.isEmpty()){
        for(Map.Entry<Integer, String> transactionEntry : toSend.entrySet()){
            Integer transactionId = transactionEntry.getKey();
            String transactionMessage = transactionEntry.getValue();
            collector.emit(new Values(transactionMessage),transactionId);
        }
        toSend.clear();
    }
    try {
        Thread.sleep(1);
    } catch (InterruptedException e) {}
}
----
Where we take all messages at the *toSend*" map and emit these using the transaction id as message id to re-send it if is needed, we can use the *clear* method safety because the fail method and the ack method where will modify the map run in the same thread-loop

Our ack method will be very simple, because the only thing that we need to do it's remove the message from our message list and our fails counter list, as we can see below

[source, java]
----
public void ack(Object msgId) {
    messages.remove(msgId);
    failCounterMessages.remove(msgId);
}
----

At the end we'll see our *fail* where we decide if we must finish the topology (because we found many errors) or we shoud re-send the message
[source, java]
----
public void fail(Object msgId) {
    Integer transactionId = (Integer) msgId;
    //Get the transactions fails
    Integer fails = failCounterMessages.get(transactionId) + 1;
    
    if(fails >= MAX_FAILS){
        //If exceeds the max fails will go down the topology
        throw new RuntimeException("Error, transaction id ["+transactionId+"] has had many errors ["+fails+"]");
    }
    
    //If not exceeds the max fails we save the new fails quantity and re-send the message 
    failCounterMessages.put(transactionId, fails);
    toSend.put(transactionId,messages.get(transactionId));
    LOG.info("Re-sending message ["+msgId+"]");
}
----
Here we can see how we use a map to count the message's fails and other map to _enqueue_ the messages that must be sended .if a message excedes the maximum fails count we will throw a _RuntimeException_ going down the topology

CAUTION: All storm nodes haven't state, so if you store information in memory (like the example) and the node goes down you will lost all stored information.

TIP: It's important to know that storm is a fast-fail system, if we throw an un-catch exeption, we'll go down our topology but If some process goes down storm we'll be able to recovery the correctly when the process is restarted

=== Getting the data

We'll see the more commons spouts implementations to collect data eficiently from different sources


==== Direct messages

This spout kind consist on connect the spouts directly to some message emmiter like the picture below

image:figs/ch04-direct-message.jpg[Direct message spout]

As we can see this architecture is very simple to implemente specially when the message emmiter is a well known device or well known devices group, we'll call well known device when we known how to access it at start time and this won't change in the topology life time, if this is a group we'll know all members at start time. As example of this architecture we will create an spout to read the twitter stream using the twitter streaming api (link:https://dev.twitter.com/docs/streaming-api[]) this api will be our message emmiter and our spout will connect to this, we will use a *filter* throught the _track_ parameter like is documented at the twitter dev page, with this spout implementation we'll get all public tweets that match with the _track_ parameter (the complete example can be found at link:https://github.com/storm-book/examples-ch04-spouts/[Twitter Example]).

To create the spout we'll get the parameters from the configuration object (tracks, user and password) and we'll create a connection (in this case using the _link:http://hc.apache.org/httpcomponents-client-ga/httpclient/apidocs/org/apache/http/impl/client/DefaultHttpClient.html[DefaultHttpClient]_ from link:http://apache.org/[Apache]) to the api when we've created the connection, we'll read one line each time and emit this line parsed from json

Here we can see the code:
[source,java]
----
public void nextTuple() {
        //Create the client
        client = new DefaultHttpClient();
        client.setCredentialsProvider(credentialProvider);
        HttpGet get = new HttpGet(STREAMING_API_URL+track);     
        HttpResponse response;
        try {
            //Execute the get
            response = client.execute(get);
            StatusLine status = response.getStatusLine();
            if(status.getStatusCode() == 200){
                InputStream inputStream = response.getEntity().getContent();
                BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));
                String in;
                //Read line by line
                while((in = reader.readLine())!=null){
                    try{
                        //Parse and emit
                        Object json = jsonParser.parse(in);
                        collector.emit(new Values(track,json));
                    }catch (ParseException e) {
                        LOG.error("Error parsing message from twitter",e);
                    }
                }
            }
        } catch (IOException e) {
            LOG.error("Error in communication with twitter api ["+get.getURI().toString()+"]");
            try {
                //Sleep before re-try the comunication
                Thread.sleep(10000);
            } catch (InterruptedException e1) {}
        } 
    }
----

This is great!!! We are reading the twitter stream but we are running this with only one spout, if this is parallelized now we'll have many spouts reading the same stream, it's not ok. So how can we paralelize the processing if we'd have many streams to read? Well one very interesting feature of storm is that we can access to the *TopologyContext* from any node then a good approach to do that is divide the streams between our spout instances like this example:

[source, java]
----
    public void open(Map conf, TopologyContext context,
            SpoutOutputCollector collector) {

        //Get the spout size from the context
        int spoutsSize = context.getComponentTasks(context.getThisComponentId()).size();

        //Identify the id of this spout
        int myIdx = context.getThisTaskIndex();

        String[] tracks = ((String) conf.get("track")).split(",");
        StringBuffer tracksBuffer = new StringBuffer();
        for(int i=0; i< tracks.length;i++){

            //Check if this spout must read the track word
            if( i % spoutsSize == myIdx){
                tracksBuffer.append(",");
                tracksBuffer.append(tracks[i]);
            }
        }
        if(tracksBuffer.length() == 0)
            throw new RuntimeException("No track found for spout" +
                    " [spoutsSize:"+spoutsSize+", tracks:"+tracks.length+"] the amount" +
                    " of tracks must be more then the spout paralellism");
        this.track =tracksBuffer.substring(1).toString();

        .........
   }
----

With this simple technic we are able to split the collectors as we want, if instead of use the twitter streaming api we are collecting
logs files from web servers, the approach is the same and we'll have an architecture like the next image:

image:figs/ch04-directconnection-hashing.jpg[]

At this moment we've saw how connect our spouts to well known devices, however It's not a constraint, we can connect our spouts to unknown devices usign the same approach saw before, but using a coordinator system to mantains the devices list, then we can detect changes on this list and create or destroy connections.  An example of this is collect web-logs from web-servers, the web-servers list is usually very variable across a web infrastructure so if we have a coordinator system and we add a server, we can detect the changes and create new connections into the spouts to get the information from new webservers. This is reprecented by the next picture.

image:figs/ch04-directconnection-coordinator.jpg[]

TIP: Although is posible connect message emiters to spouts (intead of connect the spout to the message emiter) is not recommendable. This technic create many problems because when we are running storm into a production cluster, we'll run many spouts into the single machine even in the same java virtual machine and if a machine goes down storm will start the spouts in other machine, this create several problems to maintain connections from many sites


====  Enqueued messages

text

==== DRPC

=== Conclusions
