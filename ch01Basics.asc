[[basics]]
== Basics
If you're reading this, it's because you heard about Storm somehow, and you're interested in better understanding what it does, how you can use it to solve various problems, and how it works.

This book will get you started with Storm in a very straightforward and easy way.

The first few chapters will give you a general overview of the technologies involved, some concepts you should understand so we all speak the same language, and how to install and configure Storm. The second half of the book will get you deep into spouts, bolts and topologies (more about these in a moment). The last few chapters address some more advanced features that we consider very important and interesting, like using Storm with languages that are not JVM-based.

Storm is a distributed, reliable, fault-tolerant stream processing system. The input of a Storm cluster is a stream of data handled by a node called a _spout_. The spout passes the data to a node called a _bolt_, which transforms it in some way. The bolt either persists the transformed data, or passes it to some other bolt.
You can imagine a Storm cluster as a chain of nodes (bolts), that each make some kind of transformation on the data exposed by the spout.

To illustrate this concept, here's a simple example. 

Last night I was watching the news when the announcers started to talk about politicians and their positions on various topics. They kept repeating different names, and I wondered if each name was mentioned an equal number of times, or if there was a bias in the number of mentions.
Imagine the subtitles of what the announcers were saying as your input stream of data. You could have a spout that reads this input from a file, a socket, via HTTP, etc. As lines of text arrive, the spout hands them to a bolt which separates lines of text into words. So at this stage a stream of text is converted into a stream of words. After that, another bolt compares each word to a predefined list of politician's names. On each match it increases a counter for that name in a database.
Whenever you want to see the results you just query that database, which is updated in realtime as data arrives.

image::figs/ch01-sampletopology.jpg[]

Although this is a simple example you can see how powerful Storm can be. 

The arrangement of all the nodes (spouts and bolts) and their connections is called a _topology_. Now imagine easily defining the level of parallelism for each bolt and spout, so you can scale your topology infinitely. Amazing, right?

.So what are some typical use cases for Storm?
* Processing streams: As demonstrated in the example above, unlike other stream processing systems, with Storm there's no need for queues and workers.
* Continuous computation: Send data to clients continuously so they can update and show results in real time, like site metrics, etc.
* Distributed remote processing: Easily parallelize CPU-intensive operations.

=== Components of Storm

In a Storm cluster, nodes are organized into topologies that run continuously.

There are two kind of nodes in a Storm cluster: master nodes and worker nodes. Master nodes run a daemon called _Nimbus_, which is responsible for distributing code around the cluster, assigning tasks to each worker node and monitoring for failures. Worker nodes run a daemon called _Supervisor_ which executes a portion of a topology.
A topology in Storm runs across many worker nodes on different machines.

The coordination between master and worker nodes is taken care of by a _Zookeeper_ cluster. This leads to an important design advantage: both Nimbus and Supervisor daemons are stateless, which means that if they fail or are killed, they'll start back up again like nothing happened.

Underneath, Storm makes use of 0mq (zeromq), an advanced embeddable networking library that provides wonderful features that make Storm possible.

=== Properties of Storm

Within all these design concepts and decisions, there are some really nice properties that make Storm unique.

* Simple to program: If you've ever tried doing real time processing from scratch you'll understand how painful it can become. With Storm, complexity is dramatically reduced.
* Support for multiple programming languages: It's easier to develop in a JVM-based language, but Storm supports any language as long as you use or implement a small intermediary library.
* Fault-tolerant: The Storm cluster takes care of workers going down, reassigning tasks when necessary.
* Scalable: All you need to do in order to scale is add more machines to the cluster. Storm will reassign tasks to new machines as they become available.
* Reliable: All messages are guaranteed to be processed at least once. If there are errors, messages might be processed more than once, but you'll never lose any message.
* Fast: Speed was one of the key factors driving Storm's design.
