[[a_real_life_example]]
== A Real Life Example

[[introduction]]
=== Introduction

The idea of this chapter is to illustrate a typical Web Analytics solution, a problem that is typicaly solved using a Hadoop batch job. But unless the hadoop implementation, in this solution results will be refreshed in *Real Time* thanks to the *Storm Framework*.

If you want to play as you read the chapter, please read the section: <<setup_environment, Setting Up the environment for this chapter>> before you continue.

Our example has three main components:

- A Node.JS Web Application: To play and test the system.
- A Redis Server: To persist the data.
- A Storm Topology: For real time distributed data processing.

.Architecture overview
[[FIG604]]
image::figs/ch06-real-time-analytics-system.jpg[]


==== The Node.JS Web Application

We have mocked a small and simple e-commerce website with three different pages:

- The Home Page
- The Product Page
- The Product Statistics Page

This application is implemented using the link:http://expressjs.com/[Express Framework: http://expressjs.com/]. And link:http://socket.io/[Socket.IO Framework: http://socket.io/] to push updates to the browser.

This application is intended for you to be able to play with the cluster and see the results, but it's not the focus of this book, so we wont go into more detail on that, we'll just give a description of the pages it has.

===== The Home Page

This page provides links to all the products available in the platform to ease navigation between them. It lists all the items and read them from the *Redis Server*.

link:http://localhost:3000/[URL: http://localhost:3000/]

.Home Page
[[FIG601]]
image::figs/ch06-home-page.png[]

===== The Product Page

The Product Page shows you the information related to a specific product, such as: price, title and category.

link:http://localhost:3000/product/:id[URL: http://localhost:3000/product/:id]

.Product Page
[[FIG602]]
image::figs/ch06-product-page.png[]

===== The Product Stats Page

This page will show the information computed by the storm cluster. This information will be based in the users navigating the website. The information shown by this page can be summarized as follows: Users that viewed this *Product*, also take a look to Products in those *Categories* n times.

link:http://localhost:3000/product/:id/stats[URL: http://localhost:3000/product/:id/stats]

.Product Stats View
[[FIG603]]
image::figs/ch06-stats-page.png[]

==== Starting the Node.JS Web Application

TODO: Start the application

=== The Redis Server

Redis is an advanced in memory Key Value Store with support for persistence link:http://redis.io/[Redis: http://redis.io/]. We used this server to store:

- The products information, used to serve the website.
- The User Navigation Queue, used to feed the Storm Topology.
- The Storm Topology Intermediate Data, used for the Topology to recover from failures.
- The Storm Topology Results, used to store the desired results.

==== Products information

The Redis Server will store the products in keys named with the product id and the value will be a JSON containing all the product information.

----
> redis-cli
redis 127.0.0.1:6379> get 15
"{\"title\":\"Kids smartphone cover\",\"category\":\"Covers\",\"price\":30,\"id\":15}"
----

[user_nav_queue]
==== User navigation queue

The user navigation queue is stored in a Redis list named *navigation* and organized as a FIFO. The server adds an entry to this left side of the list each time a user navigates a product page indicating who was the user and which product did he viewed. The storm cluster constantly removes elements from the right side of the list to process the information.

----
redis 127.0.0.1:6379> llen navigation
(integer) 5
redis 127.0.0.1:6379> lrange navigation 0 4
1) "{\"user\":\"59c34159-0ecb-4ef3-a56b-99150346f8d5\",\"product\":\"1\",\"type\":\"PRODUCT\"}"
2) "{\"user\":\"59c34159-0ecb-4ef3-a56b-99150346f8d5\",\"product\":\"1\",\"type\":\"PRODUCT\"}"
3) "{\"user\":\"59c34159-0ecb-4ef3-a56b-99150346f8d5\",\"product\":\"2\",\"type\":\"PRODUCT\"}"
4) "{\"user\":\"59c34159-0ecb-4ef3-a56b-99150346f8d5\",\"product\":\"3\",\"type\":\"PRODUCT\"}"
5) "{\"user\":\"59c34159-0ecb-4ef3-a56b-99150346f8d5\",\"product\":\"5\",\"type\":\"PRODUCT\"}"
----

==== Intermediate data

The cluster needs to store the history of each user separately. In order to achieve that, it saves a set in the Redis server with all the products and its categories that was navigated by each user.

----
redis 127.0.0.1:6379> smembers history:59c34159-0ecb-4ef3-a56b-99150346f8d5
1) "1:Players"
2) "5:Cameras"
3) "2:Players"
4) "3:Cameras"
----

==== Results

The cluster generates useful data about the customers viewing a specific product in a Redis Hash named "prodcnt:" followed by the product id you want to see the stats of. 

----
redis 127.0.0.1:6379> hgetall prodcnt:2
1) "Players"
2) "1"
3) "Cameras"
4) "2"
----


=== The Storm Topology

The mission of the *Storm Topology* in this system is to update the product stats in *Real Time* while the users navigate through the website.

The *Product Stats Page* is filled with a list of categories with an associated counter. The meaning of those counters is: Users that visited this product also visited products in those categories, this number of times.

This is usefull for the sellers to understand their customers needs.

Basically, the topology recieve a navigation log and updates the product stats as described in the following picture:

.Storm Topology Inputs and Outputs
[[FIG602]]
image:figs/ch06-information-flow.jpg[]

Our Storm Topology has five components: one Spout to feed it and four bolts to get the job done.

- *UsersNavigationSpout*: Reads from the users navigatio queue and feeds the topology.
- *GetCategoryBolt*: Reads the product information from the Redis Server and adds its category to the stream.
- *UserHistoryBolt*: Reads the products previously navigated by the user and emmits Product:Category pairs to update the counters in the next step.
- *ProductCategoriesCounterBolt*: Keeps track of the times that users that navigated a product, viewed a product of a specific category.
- *NewsNotifierBolt*: Notifies to the Web Application to update user interface immediatly.

Here is how the topology is created:

[source, java]
----
package storm.analytics;
...
public class TopologyStarter {
	public static void main(String[] args) {
        Logger.getRootLogger().removeAllAppenders();

		TopologyBuilder builder = new TopologyBuilder();
        
        builder.setSpout("read-feed", new UsersNavigationSpout(), 3);
        
        builder.setBolt("get-categ", new GetCategoryBolt(), 3)
						.shuffleGrouping("read-feed");
        
        builder.setBolt("user-history", new UserHistoryBolt(), 5)
						.fieldsGrouping("get-categ", new Fields("user"));
        
        builder.setBolt("product-categ-counter", new ProductCategoriesCounterBolt(), 5)
						.fieldsGrouping("user-history", new Fields("product"));
        
        builder.setBolt("news-notifier", new NewsNotifierBolt(), 5)
						.shuffleGrouping("product-categ-counter");
        
        Config conf = new Config();
        conf.setDebug(true);

        conf.put("redis-host", REDIS_HOST);
        conf.put("redis-port", REDIS_PORT);
        conf.put("webserver", WEBSERVER);
        
        LocalCluster cluster = new LocalCluster();
        cluster.submitTopology("analytics", conf, builder.createTopology());
	}
}
----


.Storm Topology
[[FIG603]]
image::figs/ch06-topology.jpg[]

==== UsersNavigationSpout

The *UsersNavigationSpout* is in charge of feeding the topology with *Navigation Entries*. Each *Navigation Entry* is a reference to a *Product Page* viewed by one user. They are stored in *Redis Server* by the *Web Application* in the way we detailed in <<user_nav_queue, User navigation queue>>.

To read the entries from the *Redis Server* we'll be using link:https://github.com/xetorthio/jedis[Jedis: https://github.com/xetorthio/jedis], a blazingly small and simple Redis client for Java.

TIP: Note that only the relevant part of the code is being shown in the following box.

[source, java]
----
package storm.analytics;

public class UsersNavigationSpout extends BaseRichSpout {
	Jedis jedis;

	...

	@Override
	public void nextTuple() {
		String content = jedis.rpop("navigation");
		if(content==null || "nil".equals(content)) {
			try { Thread.sleep(300); } catch (InterruptedException e) {}
		} else {
	        JSONObject obj=(JSONObject)JSONValue.parse(content);
	        String user = obj.get("user").toString();
	        String product = obj.get("product").toString();
	        String type = obj.get("type").toString();
	        HashMap<String, String> map = new HashMap<String, String>();
	        map.put("product", product);
	        NavigationEntry entry = new NavigationEntry(user, type, map);
	        collector.emit(new Values(user, entry));
		}
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {
		declarer.declare(new Fields("user", "otherdata"));
	}
}
----


The first action this *Spout* executes is *jedis.rpop("navigation")* this removes and returns the rightmost element in the "navigation" list in the *Redis Server*. If the list is already empty, we'll sleep for 0,3 seconds to not to hang the server whit a CPU consuming loop. If an entry is found we parse the content (remember that the content was a JSON) and map it to a *NavigationEntry* object which is just a POJO containing the entry information:

- The user that was navigating.
- The type of page that te user browsed.
- Aditional page information that depends on the type. As long as we have only the "PRODUCT" page type, additional information will be an entry for the *product* id being browsed.

We'll emmit a tuple containing this information by calling *collector.emit(new Values(user, entry))*. And the content of this tuple will be the input of the next bolt in the topology: The *GetCategoryBolt*.


==== GetCategoryBolt

This is a very simple *Bolt*. It's responsability is to deserialize the content of the tuple emited by the previoud *Spout*, if the entry is about a product page, then it'll load the product information from the *Redis Server* by using the *ProductsReader* helper class. Then, for each tuple in the input, it'll emmit a new one rearranging and adding product specific information.

Information in the output will be:

- The user.
- The product.
- The category of the product.

[source, java]
----
package storm.analytics;

public class GetCategoryBolt extends BaseBasicBolt {
	private ProductsReader reader;

	...
	@Override
	public void execute(Tuple input, BasicOutputCollector collector) {
		NavigationEntry entry = (NavigationEntry)input.getValue(1);
		if("PRODUCT".equals(entry.getPageType())){
			try {
				String product = (String)entry.getOtherData().get("product");

				// Call the items API to get item information
				Product itm = reader.readItem(product);
				if(itm ==null)
					return ;

				String categ = itm.getCategory();

				collector.emit(new Values(entry.getUserId(), product, categ));

			} catch (Exception ex) {
				System.err.println("Error processing PRODUCT tuple"+ ex);
				ex.printStackTrace();
			}
		}
	}
	...
}
----


As we said, we'll use the *ProductsReader* helper class to read the product specific information.

[source, java]
----
package storm.analytics.utilities;
...
public class ProductsReader {
	...
	public Product readItem(String id) throws Exception{
		String content= jedis.get(id);
		if(content == null  || ("nil".equals(content)))
			return null;
        Object obj=JSONValue.parse(content);
        JSONObject product=(JSONObject)obj;
        Product i= new Product((Long)product.get("id"), 
							   (String)product.get("title"), 
							   (Long)product.get("price"), 
							   (String)product.get("category"));
        return i;
    }
	...
}
----


==== UserHistoryBolt

The *UserHistoryBolt* is the core of this problem. It's responsability is to keep track of the products navigated by each user and to determine the result pairs that should be incremented.

We'll use the *Redis Server* to store the products history in a user basis, but we'll keep a local copy for performance optimization purpouses. We hided the data access details in the methods *getUserNavigationHistory(user)* and *addProductToHistory(user, prodKey)* for read and write access respectively.

[source, java]
----
package storm.analytics;
...
public class UserHistoryBolt extends BaseRichBolt{
	@Override
	public void execute(Tuple input) {
		String user = input.getString(0);
		String prod1 = input.getString(1);
		String cat1 = input.getString(2);

		// Product key will have category information embedded.
		String prodKey = prod1+":"+cat1;
		
		Set<String> productsNavigated = getUserNavigationHistory(user);
		
		// If the user previously navigated this item -> ignore it
		if(!productsNavigated.contains(prodKey)) {
			
			// Otherwise update related items
			for (String other : productsNavigated) {
				String [] ot = other.split(":");
				String prod2 = ot[0];
				String cat2 = ot[1]; 
				collector.emit(new Values(prod1, cat2));
				collector.emit(new Values(prod2, cat1));
			}
			addProductToHistory(user, prodKey);
		}
	}
}
----

Note that the desired output of this *Bolt* is to emmit the products whose categories relations should be incremented.

Let's take a look at the source code. This *Bolt* keeps a set of the product navigated by each user. Please note that the *set* is filled with product:category pairs instead of just the product. That's because we'll need the category information in future calls and it wont be performant to get them from the database again each time. That is possible because the products only have one category and it wont change during que product life.

After reading the set of the user's previously navigated products (with their categories) we'll check if current product has been previously visited. If that's the case, this entry will be ignored. If this is the first time the user watches at this product, then we'll iterate the users history and emmit a tuple for the product being navigated and the categories of all he products in the history *collector.emit(new Values(prod1, cat2))* and another tuple for the other products and the category of the product being navigated *collector.emit(new Values(prod2, cat1))*. Finally we'll add the produt (with it's category) in the set.

To review this behavior, lets follow this example:

Let's assume that the user *John* has this navigation history:

[width="40%", frame="topbot",options="header"]
|======================
|User | # | Category
|John | 0 | Players
|John | 2 | Players
|John | 17 | TVs
|John | 21 | Mounts
|======================

And the following navigation entry needs to be processed:


[width="40%", frame="topbot",options="header"]
|======================
|User | # | Category
|John | 8 | Phones
|======================

The user didn't navigated the product 8 previously, so we'll need to procees it.

As a result the emmited tuples will be:

[width="40%", frame="topbot",options="header"]
|======================
| # | Category
| 8 | Players
| 8 | Players
| 8 | TVs
| 8 | Mounts
| 0 | Phones
| 2 | Phones
| 17 | Phones
| 21 | Phones
|======================

Meaning that the relation between the products in the left and the categories in the right should be incremented in one unit.

Lets now explore the persistence in this Bolt.

[source, java]
----
public class UserHistoryBolt extends BaseRichBolt{
	...
	private Set<String> getUserNavigationHistory(String user) {
		Set<String> userHistory = usersNavigatedItems.get(user);
		if(userHistory == null) {
			userHistory = jedis.smembers(buildKey(user));
			if(userHistory == null) 
				userHistory = new HashSet<String>();
			usersNavigatedItems.put(user, userHistory);
		}
		return userHistory;
	}

	private void addProductToHistory(String user, String product) {
		Set<String> userHistory = getUserNavigationHistory(user);
		userHistory.add(product);
		jedis.sadd(buildKey(user), product);
	}
	...
}
----

The *getUserNavigationHistory* will return the desired set of product that the user has previously navigated. The first try will be to get it from the local memory *usersNavigatedItems.get(user)* but if the history of this user is not in memory, it'll read from the *Redis Server* using *jedis.smembers(buildKey(user))*i and add the entry to the memory structure *usersNavigatedItems*.

Only when a new product is navigated by the user the *addProductToHistory* is called and it updates both, the memory structure *userHistory.add(product)* and the *Redis Server* structure: *jedis.sadd(buildKey(user), product)*.

Note that, as long as this bolts keeps in memory information in a user basis, it is very important that when we parallelize it we use *fieldsGrouping* by user in the first degree, otherwise different copies of the user history will be available and inconsistencies will occur.


==== ProductCategoriesCounterBolt

The *ProductCategoriesCounterBolt* is in charge of keeping track of all the products related categories. It'll recieve the product-category pairs emmited by the *UsersHistoryBolt* and update the counters.

The information about the number of occurrences each pair has is kept in the *Redis Server* but, a local cache for reads and a write buffer is kept for performance issues and the information is downloaded to *Redis* in a background thread.

This bolt will also emmit a tuple with the updated counter for the input pair. The purpouse of this tuple to be emmited is to feed the next bolt in the topology *NewsNotifierBolt* in charge of broadcasting the news to the final users for real time updates.

[source, java]
----
public class ProductCategoriesCounterBolt extends BaseRichBolt {
	...
	@Override
	public void execute(Tuple input) {
		String product = input.getString(0);
		String categ = input.getString(1);
		int total = count(product, categ);
		collector.emit(new Values(product, categ, total));
	}
	...
	private int count(String product, String categ) {
		int count = getProductCategoryCount(categ, product);
		count ++;
		storeProductCategoryCount(categ, product, count);
		return count;
	}
	...
}
----

Persistence in this bolt is hidden in the *getProductCategoryCount* and *storeProductCategoryCount* methods. Let's take a look inside them:

[source, java]
----
package storm.analytics;
...
public class ProductCategoriesCounterBolt extends BaseRichBolt {
	// ITEM:CATEGORY -> COUNT
	HashMap<String, Integer> counter = new HashMap<String, Integer>();
	
	// ITEM:CATEGORY -> COUNT
	HashMap<String, Integer> pendingToSave = new HashMap<String, Integer>(); 

	...
	public int getProductCategoryCount(String categ, String product) {
		Integer count = counter.get(buildLocalKey(categ, product));
		if(count == null) {
			String sCount = jedis.hget(buildRedisKey(product), categ);
			if(sCount == null || "nil".equals(sCount)) {
				count = 0;
			} else {
				count = Integer.valueOf(sCount);
			}
		}
		return count;
	}
	...
	private void storeProductCategoryCount(String categ, String product, int count) {
		String key = buildLocalKey(categ, product);
		counter.put(key , count);
		synchronized (pendingToSave) {
			pendingToSave.put(key, count);	
		}
	}
	...
}
----

The *getProductCategoryCount* will first try to read the in memory cache *counter*.  If the information is not available there, it'll look for the information in the *Redis Server*.

The *storeProductCategoryCount* will update the *counter* cache and the *pendingToSave* buffer. The buffer will be persisted by the following bkground thread:

[source, java]
----
package storm.analytics;

public class ProductCategoriesCounterBolt extends BaseRichBolt {
...
	private void startDownloaderThread() {
		TimerTask t = new TimerTask() {
			@Override
			public void run() {
				HashMap<String, Integer> pendings;
				synchronized (pendingToSave) {
					pendings = pendingToSave;
					pendingToSave = new HashMap<String, Integer>();
				}
				
				for (String key : pendings.keySet()) {
					String[] keys = key.split(":");
					String product = keys[0];
					String categ = keys[1];
					Integer count = pendings.get(key);
					jedis.hset(buildRedisKey(product), categ, count.toString());
				}
			}
		};
		timer = new Timer("Item categories downloader");
		timer.scheduleAtFixedRate(t, downloadTime, downloadTime);
	}
...
}
----

The download thread will lock the *pendingToSave* and create a new empty buffer for the other threads to use it while it downloads the old one to *Redis*. This code block runs each *downloadTime* milliseconds and is configurable through the *download-time* topology configuration parameter. The longer the *download-time* is, less the writes to the *Redis* are performed because consecutive adds to a pair are written just once.

Keep in mind that again, as in the previous bolt, it is extrmely important to apply correct fields grouping when assigning the sources to this bolt, in this case grouping by product. That's because it stores in memory copies of the information in a product basis and if several copies of the cache and the buffer exists there will be inconsistencies.


==== NewsNotifierBolt

The *NewsNotifierBolt* is in charge of notifying the *Web Application* of the changes in the stats, in order for it to notify the users viewing the stats at this precise moment. Notification will be an HTTP POST using the link:http://hc.apache.org/httpcomponents-client-ga/httpclient/index.html[Apache HttpClient] to the URL configured in the *webserver* parameter of the topology configuration. The POST content will be encoded in JSON.

This bolt is removed from the topology when testing.

[source, java]
----
package storm.analytics;
...
public class NewsNotifierBolt extends BaseRichBolt {
	...
	@Override
	public void execute(Tuple input) {
		String product = input.getString(0);
		String categ = input.getString(1);
		int visits = input.getInteger(2);

		String content = "{ \"product\": \""+product+"\", \"categ\":\""+categ+"\", \"visits\":"+visits+" }";

		HttpPost post = new HttpPost(webserver);
		try {
			post.setEntity(new StringEntity(content));
			HttpResponse response = client.execute(post);
			org.apache.http.util.EntityUtils.consume(response.getEntity());
		} catch (Exception e) {
			e.printStackTrace();
			reconnect();
		} 
	}
	...
}
----


=== Testing the topology

In order to test the topology we will use the provided *LocalCluster* and a local *Redis Server*. We'll also populate the products database on the init and mock the insertion of navigation logs in the *Redis Server*. Our assertions will be performed by reading the topology outputs to the *Redis Server*. Tests are written in Java & Groovy.

.The testing Architecture
[[FIG604]]
image:figs/ch06-test-architecture.jpg[]

==== Tests initialization 

Initialization consists of three steps:

1) Flushing the *Local Redis Server*.
2) Populate the products
3) Start the *LocalCluster* and submit the *Topology*.

Initialization is implemented in the *AbstractAnalyticsTest*. All the tests implements this class. Initialization has a static flag *topologyStarted* in order to not to run several times when multiple classes implementing *AbstractAnalyticsTest* are instantiated.

The *sleep* sentence is to let the *LocalCluster* start correctly before start expecting results from it.

[source, java]
----
public abstract class AbstractAnalyticsTest extends Assert {
    def jedis
    static topologyStarted = false
    static sync= new Object()

    private void reconnect() {
        jedis = new Jedis(TopologyStarter.REDIS_HOST, TopologyStarter.REDIS_PORT)
    }

    @Before
    public void startTopology(){
        synchronized(sync){
            reconnect()
            if(!topologyStarted){
                jedis.flushAll()
                populateProducts()
                TopologyStarter.testing = true
                TopologyStarter.main(null)
                topologyStarted = true
                sleep 1000
            }
        }
    }

	...
	public void populateProducts() {
        def testProducts = [
            [id: 0, title:"Dvd player with surround sound system", category:"Players", price: 100],
            [id: 1, title:"Full HD Bluray and DVD player", category:"Players", price:130],
            [id: 2, title:"Media player with USB 2.0 input", category:"Players", price:70],
			...	
            [id: 21, title:"TV Wall mount bracket 50-55 Inches", category:"Mounts", price:80]
        ]

        testProducts.each() { product ->
            def val = "{ \"title\": \"${product.title}\" , \"category\": \"${product.category}\"," + 
						" \"price\": ${product.price}, \"id\": ${product.id} }"
            println val
            jedis.set(product.id.toString(), val.toString())
        }
    }
	...
}
----

In order for the different tests to have a way to emulate the behavior of a user navigating the website, we implemente a method called *navigate* in the *AbstractAnalyticsTest* class to insert navigation entries in the *Redis Server* navigation queue.

[source, java]
----
public abstract class AbstractAnalyticsTest extends Assert {
	...
    public void navigate(user, product) {
        String nav= "{\"user\": \"${user}\", \"product\": \"${product}\", \"type\": \"PRODUCT\"}".toString()
        println "Pushing navigation: ${nav}"
        jedis.lpush('navigation', nav)
    }
	...
}
----

Different tests will also need to assert against the stats results, in order to check if the topology is behaving as expected. For this purpouse we provide a method called *getProductCategoryStats* in the *AbstractAnalyticsTest* that will read a specific relation from the *Redis Server*.

[source, java]
----
public abstract class AbstractAnalyticsTest extends Assert {
	...
    public int getProductCategoryStats(String product, String categ) {
        String count = jedis.hget("prodcnt:${product}", categ)
        if(count == null || "nil".equals(count))
            return 0
        return Integer.valueOf(count)
    }
	...
}
----

==== A test example

In the next snippet we emulate a few product navigations of the user "1" and after that we assert the results. Note that we wait for 2 seconds before asserting, this is to be sure that results has been downloaded to redis. Remember that the *ProductCategoriesCounterBolt* has a memory copy of the counters and download them in background.

[source, java]
----
package functional

class StatsTest extends AbstractAnalyticsTest {
    @Test
    public void testNoDuplication(){
        navigate("1", "0") // Players
        navigate("1", "1") // Players
        navigate("1", "2") // Players
        navigate("1", "3") // Cameras

        Thread.sleep(2000) // Give two seconds for the system to process the data.

        assertEquals 1, getProductCategoryStats("0", "Cameras")
        assertEquals 1, getProductCategoryStats("1", "Cameras")
        assertEquals 1, getProductCategoryStats("2", "Cameras")
        assertEquals 2, getProductCategoryStats("0", "Players")
        assertEquals 3, getProductCategoryStats("3", "Players")
    }
}
----

